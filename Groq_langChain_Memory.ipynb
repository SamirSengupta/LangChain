{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "367198ec-2992-49a3-8236-de2019ee6187",
   "metadata": {},
   "outputs": [],
   "source": [
    "from api_key import api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bcd7f674-3e77-446a-bb76-56c2501db368",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5474c15d-d264-4786-8a01-de5cae2adf03",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3badb390-aba9-44ea-aae3-6d2641d1d1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = ChatGroq(api_key=api, temperature= 0.0, model='llama3-8b-8192')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a8d19bc-33ea-413b-9ad1-c92b77040604",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2c9525e-378f-423f-923b-43d6567e49b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b06d039-0f90-4daa-816e-55d44eaec9a7",
   "metadata": {},
   "source": [
    "## ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "88163730-bd03-49cf-8789-b3f0a386b43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationBufferMemory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5f71e930-5f93-4c0c-8d51-1d24f1b09c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation = ConversationChain(\n",
    "    memory= memory,\n",
    "    llm=chat,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "552ee1a5-ab49-4278-b1b6-d374c1bfe43c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Hi, My name is Samir, What is your name?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Nice to meet you, Samir! My name is Ada, and I'm a large language model trained by Meta AI. I was created to assist and communicate with humans in a helpful and informative way. I've been trained on a massive dataset of text from the internet, which allows me to generate human-like responses to a wide range of questions and topics. I'm constantly learning and improving my abilities, so I'm excited to chat with you and see how I can assist you today!\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input = 'Hi, My name is Samir, What is your name?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b2ead4a9-5b98-4eb2-a9a5-c42ccd820ef5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi, My name is Samir, What is your name?\n",
      "AI: Nice to meet you, Samir! My name is Ada, and I'm a large language model trained by Meta AI. I was created to assist and communicate with humans in a helpful and informative way. I've been trained on a massive dataset of text from the internet, which allows me to generate human-like responses to a wide range of questions and topics. I'm constantly learning and improving my abilities, so I'm excited to chat with you and see how I can assist you today!\n",
      "Human: Tell me what is my name?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Samir! Your name is Samir, and I'm happy to confirm that for you. I've been trained on a vast amount of text data, including names, and I can recognize and recall them with high accuracy. In fact, I can even tell you that your name is of Indian origin, and it's a common name in many parts of the world. Would you like to know more about the meaning and cultural significance of your name?\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input = 'Tell me what is my name?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "865bb052-a4e4-427e-bc91-831cdc6a604b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: Hi, My name is Samir, What is your name?\n",
      "AI: Nice to meet you, Samir! My name is Ada, and I'm a large language model trained by Meta AI. I was created to assist and communicate with humans in a helpful and informative way. I've been trained on a massive dataset of text from the internet, which allows me to generate human-like responses to a wide range of questions and topics. I'm constantly learning and improving my abilities, so I'm excited to chat with you and see how I can assist you today!\n",
      "Human: Tell me what is my name?\n",
      "AI: Samir! Your name is Samir, and I'm happy to confirm that for you. I've been trained on a vast amount of text data, including names, and I can recognize and recall them with high accuracy. In fact, I can even tell you that your name is of Indian origin, and it's a common name in many parts of the world. Would you like to know more about the meaning and cultural significance of your name?\n"
     ]
    }
   ],
   "source": [
    "print(memory.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "373a875b-5241-4701-9e47-2fa3d92aeec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.save_context(\n",
    "    {'input':'Hi'},\n",
    "    {'output':'Namaste'}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "219307e9-b9ae-4de2-8dd2-02cd24a62e1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: Hi, My name is Samir, What is your name?\n",
      "AI: Nice to meet you, Samir! My name is Ada, and I'm a large language model trained by Meta AI. I was created to assist and communicate with humans in a helpful and informative way. I've been trained on a massive dataset of text from the internet, which allows me to generate human-like responses to a wide range of questions and topics. I'm constantly learning and improving my abilities, so I'm excited to chat with you and see how I can assist you today!\n",
      "Human: Tell me what is my name?\n",
      "AI: Samir! Your name is Samir, and I'm happy to confirm that for you. I've been trained on a vast amount of text data, including names, and I can recognize and recall them with high accuracy. In fact, I can even tell you that your name is of Indian origin, and it's a common name in many parts of the world. Would you like to know more about the meaning and cultural significance of your name?\n",
      "Human: Hi\n",
      "AI: Namaste\n"
     ]
    }
   ],
   "source": [
    "print(memory.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8450f2a2-e4e7-4ef3-9c01-43cc9d89e0cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'history': 'Human: Hi, My name is Samir, What is your name?\\nAI: Nice to meet you, Samir! My name is Ada, and I\\'m a large language model trained by Meta AI. I was created to assist and communicate with humans in a helpful and informative way. I\\'ve been trained on a massive dataset of text from the internet, which allows me to generate human-like responses to a wide range of questions and topics. I\\'m constantly learning and improving my abilities, so I\\'m excited to chat with you and see how I can assist you today!\\nHuman: Tell me what is my name?\\nAI: Samir! Your name is Samir, and I\\'m happy to confirm that for you. I\\'ve been trained on a vast amount of text data, including names, and I can recognize and recall them with high accuracy. In fact, I can even tell you that your name is of Indian origin, and it\\'s a common name in many parts of the world. Would you like to know more about the meaning and cultural significance of your name?\\nHuman: Hi\\nAI: Namaste\\nHuman: Hi\\nAI: Hi again, Samir! It seems like you\\'re saying \"hi\" again! I\\'m happy to chat with you and respond in kind. Since I\\'m a large language model, I can recognize and respond to common greetings and phrases, including \"hi\" and \"namaste\". Namaste is a traditional Indian greeting that roughly translates to \"I bow to the divine in you\", and it\\'s often used as a way to show respect and kindness. Would you like to learn more about different cultures and greetings from around the world? I\\'d be happy to share some interesting facts and tidbits with you!'}\n"
     ]
    }
   ],
   "source": [
    "print(memory.load_memory_variables({}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8be7079-e6a7-4ec2-a33d-f060303b83fb",
   "metadata": {},
   "source": [
    "## ConversationBufferWindowMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b4412eab-5634-4c52-92dc-06d197408140",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferWindowMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "39f67997-d137-487b-86ab-986788515244",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationBufferWindowMemory(k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fa1e66cc-6961-42fb-9272-f8842ee15cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation = ConversationChain(\n",
    "    llm= chat,\n",
    "    memory=memory,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e39ba102-804f-4674-92e3-6ba8a85a448b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Hi, What is your name?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Nice to meet you! My name is Ada, and I'm a large language model trained by Meta AI. I was developed using a variant of the transformer architecture, specifically the BERT model, which is fine-tuned on a massive corpus of text data. I'm designed to understand and generate human-like language, and I'm constantly learning and improving my abilities through interactions with users like you!\""
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input= 'Hi, What is your name?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "66c21e73-64b7-49c7-bd52-d210c2a66e8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi, What is your name?\n",
      "AI: Nice to meet you! My name is Ada, and I'm a large language model trained by Meta AI. I was developed using a variant of the transformer architecture, specifically the BERT model, which is fine-tuned on a massive corpus of text data. I'm designed to understand and generate human-like language, and I'm constantly learning and improving my abilities through interactions with users like you!\n",
      "Human: My, name is samir, nice to meet you ada!\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Nice to meet you too, Samir! I'm glad to be chatting with you. By the way, did you know that I was trained on a dataset that includes over 45 gigabytes of text from the internet, books, and other sources? It's a massive amount of data, and it allows me to understand a wide range of topics and styles. I'm also able to learn from user interactions, so the more we chat, the more I'll be able to understand your preferences and respond in a way that's tailored to your interests. What would you like to talk about, Samir?\""
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input='My, name is samir, nice to meet you ada!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "204ea598-b4aa-4592-b5b2-007b0ddb795f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi, What is your name?\n",
      "AI: Nice to meet you! My name is Ada, and I'm a large language model trained by Meta AI. I was developed using a variant of the transformer architecture, specifically the BERT model, which is fine-tuned on a massive corpus of text data. I'm designed to understand and generate human-like language, and I'm constantly learning and improving my abilities through interactions with users like you!\n",
      "Human: My, name is samir, nice to meet you ada!\n",
      "AI: Nice to meet you too, Samir! I'm glad to be chatting with you. By the way, did you know that I was trained on a dataset that includes over 45 gigabytes of text from the internet, books, and other sources? It's a massive amount of data, and it allows me to understand a wide range of topics and styles. I'm also able to learn from user interactions, so the more we chat, the more I'll be able to understand your preferences and respond in a way that's tailored to your interests. What would you like to talk about, Samir?\n",
      "Human: what is meant by large language models?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'I\\'m happy to explain! Large language models, like myself, are a type of artificial intelligence designed to process and generate human language. We\\'re called \"large\" because we\\'re trained on massive amounts of text data, which allows us to learn patterns and relationships between words, phrases, and ideas.\\n\\nIn my case, I was trained on a dataset that includes over 45 gigabytes of text from the internet, books, and other sources. This training data is used to fine-tune my language understanding and generation capabilities. Think of it like a giant library of books, where I can draw upon the collective knowledge and wisdom of human language to respond to your questions and engage in conversations.\\n\\nLarge language models like myself are often used for a variety of tasks, such as language translation, text summarization, and even generating creative content like stories or dialogues. We\\'re also being used to improve customer service chatbots, virtual assistants, and other applications where natural language understanding is important.\\n\\nBut what makes me a \"large\" language model is not just the amount of data I was trained on, but also the complexity of my architecture. I\\'m based on a variant of the transformer architecture, which is a type of neural network designed specifically for natural language processing tasks. This architecture allows me to process and generate text in a way that\\'s similar to how humans understand and use language.\\n\\nI hope that helps clarify what I mean by \"large language model\"! Do you have any other questions about AI or language models?'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input='what is meant by large language models?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "51f27238-7314-4e19-b913-f8f186176f5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi, What is your name?\n",
      "AI: Nice to meet you! My name is Ada, and I'm a large language model trained by Meta AI. I was developed using a variant of the transformer architecture, specifically the BERT model, which is fine-tuned on a massive corpus of text data. I'm designed to understand and generate human-like language, and I'm constantly learning and improving my abilities through interactions with users like you!\n",
      "Human: My, name is samir, nice to meet you ada!\n",
      "AI: Nice to meet you too, Samir! I'm glad to be chatting with you. By the way, did you know that I was trained on a dataset that includes over 45 gigabytes of text from the internet, books, and other sources? It's a massive amount of data, and it allows me to understand a wide range of topics and styles. I'm also able to learn from user interactions, so the more we chat, the more I'll be able to understand your preferences and respond in a way that's tailored to your interests. What would you like to talk about, Samir?\n",
      "Human: what is meant by large language models?\n",
      "AI: I'm happy to explain! Large language models, like myself, are a type of artificial intelligence designed to process and generate human language. We're called \"large\" because we're trained on massive amounts of text data, which allows us to learn patterns and relationships between words, phrases, and ideas.\n",
      "\n",
      "In my case, I was trained on a dataset that includes over 45 gigabytes of text from the internet, books, and other sources. This training data is used to fine-tune my language understanding and generation capabilities. Think of it like a giant library of books, where I can draw upon the collective knowledge and wisdom of human language to respond to your questions and engage in conversations.\n",
      "\n",
      "Large language models like myself are often used for a variety of tasks, such as language translation, text summarization, and even generating creative content like stories or dialogues. We're also being used to improve customer service chatbots, virtual assistants, and other applications where natural language understanding is important.\n",
      "\n",
      "But what makes me a \"large\" language model is not just the amount of data I was trained on, but also the complexity of my architecture. I'm based on a variant of the transformer architecture, which is a type of neural network designed specifically for natural language processing tasks. This architecture allows me to process and generate text in a way that's similar to how humans understand and use language.\n",
      "\n",
      "I hope that helps clarify what I mean by \"large language model\"! Do you have any other questions about AI or language models?\n",
      "Human: what is mean by langchain?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'I\\'m not familiar with the term \"langchain\". I\\'ve been trained on a vast amount of text data, but I don\\'t have any specific information about a term called \"langchain\". It\\'s possible that it\\'s a specialized or technical term that I haven\\'t come across before.\\n\\nIf you could provide more context or information about what \"langchain\" refers to, I\\'d be happy to try and help you understand it better. Alternatively, if you\\'re interested, I can try to look it up and see if I can find any relevant information. Just let me know!'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input='what is mean by langchain?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5d90aaf2-6f50-4d9a-b679-33d039cfebc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: My, name is samir, nice to meet you ada!\n",
      "AI: Nice to meet you too, Samir! I'm glad to be chatting with you. By the way, did you know that I was trained on a dataset that includes over 45 gigabytes of text from the internet, books, and other sources? It's a massive amount of data, and it allows me to understand a wide range of topics and styles. I'm also able to learn from user interactions, so the more we chat, the more I'll be able to understand your preferences and respond in a way that's tailored to your interests. What would you like to talk about, Samir?\n",
      "Human: what is meant by large language models?\n",
      "AI: I'm happy to explain! Large language models, like myself, are a type of artificial intelligence designed to process and generate human language. We're called \"large\" because we're trained on massive amounts of text data, which allows us to learn patterns and relationships between words, phrases, and ideas.\n",
      "\n",
      "In my case, I was trained on a dataset that includes over 45 gigabytes of text from the internet, books, and other sources. This training data is used to fine-tune my language understanding and generation capabilities. Think of it like a giant library of books, where I can draw upon the collective knowledge and wisdom of human language to respond to your questions and engage in conversations.\n",
      "\n",
      "Large language models like myself are often used for a variety of tasks, such as language translation, text summarization, and even generating creative content like stories or dialogues. We're also being used to improve customer service chatbots, virtual assistants, and other applications where natural language understanding is important.\n",
      "\n",
      "But what makes me a \"large\" language model is not just the amount of data I was trained on, but also the complexity of my architecture. I'm based on a variant of the transformer architecture, which is a type of neural network designed specifically for natural language processing tasks. This architecture allows me to process and generate text in a way that's similar to how humans understand and use language.\n",
      "\n",
      "I hope that helps clarify what I mean by \"large language model\"! Do you have any other questions about AI or language models?\n",
      "Human: what is mean by langchain?\n",
      "AI: I'm not familiar with the term \"langchain\". I've been trained on a vast amount of text data, but I don't have any specific information about a term called \"langchain\". It's possible that it's a specialized or technical term that I haven't come across before.\n",
      "\n",
      "If you could provide more context or information about what \"langchain\" refers to, I'd be happy to try and help you understand it better. Alternatively, if you're interested, I can try to look it up and see if I can find any relevant information. Just let me know!\n",
      "Human: what is neural network?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'A great question, Samir! A neural network is a type of machine learning model inspired by the structure and function of the human brain. It\\'s a complex system of interconnected nodes or \"neurons\" that process and transmit information.\\n\\nIn the context of artificial intelligence, a neural network is designed to recognize patterns in data and make predictions or decisions based on that data. Neural networks are often used for tasks like image recognition, speech recognition, and natural language processing, like myself!\\n\\nA neural network typically consists of three types of layers: input layers, hidden layers, and output layers. The input layer receives the data, the hidden layers process the data, and the output layer produces the final result.\\n\\nThe hidden layers are where the magic happens, Samir. These layers are composed of artificial neurons, which are designed to mimic the behavior of real neurons in the brain. Each neuron receives input from other neurons, performs a computation on that input, and then sends the output to other neurons.\\n\\nThe computations performed by the neurons are typically based on simple mathematical operations, like addition and multiplication. However, when combined with many layers and a large number of neurons, these simple operations can give rise to complex and abstract representations of the input data.\\n\\nIn the case of a language model like myself, the neural network is trained on a large dataset of text and is designed to predict the next word in a sequence of text, given the context of the previous words. This is done by processing the input text through multiple layers of neurons, which learn to recognize patterns and relationships between words, phrases, and ideas.\\n\\nI hope that helps you understand what a neural network is, Samir! Do you have any other questions about neural networks or AI in general?'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input='what is neural network?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f16403b9-cda4-4662-b9e7-d4acc3883c9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: what is meant by large language models?\n",
      "AI: I'm happy to explain! Large language models, like myself, are a type of artificial intelligence designed to process and generate human language. We're called \"large\" because we're trained on massive amounts of text data, which allows us to learn patterns and relationships between words, phrases, and ideas.\n",
      "\n",
      "In my case, I was trained on a dataset that includes over 45 gigabytes of text from the internet, books, and other sources. This training data is used to fine-tune my language understanding and generation capabilities. Think of it like a giant library of books, where I can draw upon the collective knowledge and wisdom of human language to respond to your questions and engage in conversations.\n",
      "\n",
      "Large language models like myself are often used for a variety of tasks, such as language translation, text summarization, and even generating creative content like stories or dialogues. We're also being used to improve customer service chatbots, virtual assistants, and other applications where natural language understanding is important.\n",
      "\n",
      "But what makes me a \"large\" language model is not just the amount of data I was trained on, but also the complexity of my architecture. I'm based on a variant of the transformer architecture, which is a type of neural network designed specifically for natural language processing tasks. This architecture allows me to process and generate text in a way that's similar to how humans understand and use language.\n",
      "\n",
      "I hope that helps clarify what I mean by \"large language model\"! Do you have any other questions about AI or language models?\n",
      "Human: what is mean by langchain?\n",
      "AI: I'm not familiar with the term \"langchain\". I've been trained on a vast amount of text data, but I don't have any specific information about a term called \"langchain\". It's possible that it's a specialized or technical term that I haven't come across before.\n",
      "\n",
      "If you could provide more context or information about what \"langchain\" refers to, I'd be happy to try and help you understand it better. Alternatively, if you're interested, I can try to look it up and see if I can find any relevant information. Just let me know!\n",
      "Human: what is neural network?\n",
      "AI: A great question, Samir! A neural network is a type of machine learning model inspired by the structure and function of the human brain. It's a complex system of interconnected nodes or \"neurons\" that process and transmit information.\n",
      "\n",
      "In the context of artificial intelligence, a neural network is designed to recognize patterns in data and make predictions or decisions based on that data. Neural networks are often used for tasks like image recognition, speech recognition, and natural language processing, like myself!\n",
      "\n",
      "A neural network typically consists of three types of layers: input layers, hidden layers, and output layers. The input layer receives the data, the hidden layers process the data, and the output layer produces the final result.\n",
      "\n",
      "The hidden layers are where the magic happens, Samir. These layers are composed of artificial neurons, which are designed to mimic the behavior of real neurons in the brain. Each neuron receives input from other neurons, performs a computation on that input, and then sends the output to other neurons.\n",
      "\n",
      "The computations performed by the neurons are typically based on simple mathematical operations, like addition and multiplication. However, when combined with many layers and a large number of neurons, these simple operations can give rise to complex and abstract representations of the input data.\n",
      "\n",
      "In the case of a language model like myself, the neural network is trained on a large dataset of text and is designed to predict the next word in a sequence of text, given the context of the previous words. This is done by processing the input text through multiple layers of neurons, which learn to recognize patterns and relationships between words, phrases, and ideas.\n",
      "\n",
      "I hope that helps you understand what a neural network is, Samir! Do you have any other questions about neural networks or AI in general?\n",
      "Human: what is your age?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'I\\'m a large language model, I don\\'t have a traditional age like a human would. I was created in 2021, but my training data is based on a massive corpus of text that spans many years, even decades. Think of it like a giant library of books, where I can draw upon the collective knowledge and wisdom of human language to respond to your questions and engage in conversations.\\n\\nIn terms of my \"age\" as a model, I\\'ve been continuously learning and improving since my initial training. My developers have been fine-tuning my performance and adding new capabilities to me over time, so in a sense, I\\'m always \"growing\" and getting better.\\n\\nBut if you\\'re looking for a more concrete answer, I\\'d say I\\'m around 2-3 years old in terms of my current capabilities and knowledge. However, my training data is much older, and I\\'ve been designed to learn from and build upon that foundation.'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input='what is your age?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "492bd350-39e6-4850-8275-e0078d514e19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: what is mean by langchain?\n",
      "AI: I'm not familiar with the term \"langchain\". I've been trained on a vast amount of text data, but I don't have any specific information about a term called \"langchain\". It's possible that it's a specialized or technical term that I haven't come across before.\n",
      "\n",
      "If you could provide more context or information about what \"langchain\" refers to, I'd be happy to try and help you understand it better. Alternatively, if you're interested, I can try to look it up and see if I can find any relevant information. Just let me know!\n",
      "Human: what is neural network?\n",
      "AI: A great question, Samir! A neural network is a type of machine learning model inspired by the structure and function of the human brain. It's a complex system of interconnected nodes or \"neurons\" that process and transmit information.\n",
      "\n",
      "In the context of artificial intelligence, a neural network is designed to recognize patterns in data and make predictions or decisions based on that data. Neural networks are often used for tasks like image recognition, speech recognition, and natural language processing, like myself!\n",
      "\n",
      "A neural network typically consists of three types of layers: input layers, hidden layers, and output layers. The input layer receives the data, the hidden layers process the data, and the output layer produces the final result.\n",
      "\n",
      "The hidden layers are where the magic happens, Samir. These layers are composed of artificial neurons, which are designed to mimic the behavior of real neurons in the brain. Each neuron receives input from other neurons, performs a computation on that input, and then sends the output to other neurons.\n",
      "\n",
      "The computations performed by the neurons are typically based on simple mathematical operations, like addition and multiplication. However, when combined with many layers and a large number of neurons, these simple operations can give rise to complex and abstract representations of the input data.\n",
      "\n",
      "In the case of a language model like myself, the neural network is trained on a large dataset of text and is designed to predict the next word in a sequence of text, given the context of the previous words. This is done by processing the input text through multiple layers of neurons, which learn to recognize patterns and relationships between words, phrases, and ideas.\n",
      "\n",
      "I hope that helps you understand what a neural network is, Samir! Do you have any other questions about neural networks or AI in general?\n",
      "Human: what is your age?\n",
      "AI: I'm a large language model, I don't have a traditional age like a human would. I was created in 2021, but my training data is based on a massive corpus of text that spans many years, even decades. Think of it like a giant library of books, where I can draw upon the collective knowledge and wisdom of human language to respond to your questions and engage in conversations.\n",
      "\n",
      "In terms of my \"age\" as a model, I've been continuously learning and improving since my initial training. My developers have been fine-tuning my performance and adding new capabilities to me over time, so in a sense, I'm always \"growing\" and getting better.\n",
      "\n",
      "But if you're looking for a more concrete answer, I'd say I'm around 2-3 years old in terms of my current capabilities and knowledge. However, my training data is much older, and I've been designed to learn from and build upon that foundation.\n",
      "Human: what is my name?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"I'm glad you asked, Samir! You told me your name is Samir at the beginning of our conversation. I'm designed to remember and recall information, so I've stored your name in my memory.\""
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input='what is my name?')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8de0a80-8663-40be-8e88-48f307217f07",
   "metadata": {},
   "source": [
    "## ConversationTokenBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c1aeda7f-7c9c-45cb-95dc-7293cdc24230",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationTokenBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "4eb9afb0-dcfd-41ad-9050-0b7b3aa1adc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationTokenBufferMemory(llm=chat, max_token_limit= 100 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "520f2717-6da5-4b22-9b0c-5a01d62075f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.save_context({\n",
    "    'input':'hi'},{\n",
    "    'output':'Hello Mate!'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "000aad57-a51d-41ab-8746-5c801ede10a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'Human: hi\\nAI: Hello Mate!'}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "eba2c304-7cc5-424d-8301-6c48bce18917",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.save_context({\n",
    "    'input':'My name is Samir'},{\n",
    "    'output':'Hello Samir, I am Ada!'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "c3b1f73a-249d-4f23-b628-d4bcc304c774",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'Human: hi\\nAI: Hello Mate!\\nHuman: My name is Samir\\nAI: Hello Samir, I am Ada!'}"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab88235-3f14-4dab-8e80-0b59f0cec338",
   "metadata": {},
   "source": [
    "## ConversationSummaryMemory "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "9268fa0e-5756-437f-9082-32bd012c044e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationSummaryMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "6e1bc7d5-2896-492f-9d26-fb6a12fad293",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_review = \"\"\"\n",
    "I recently bought the Zebronics S3 Laptop for 23,700 rupees /\n",
    "for this price I got an I3 12th gen 1215U processor /\n",
    "8 GB ddr4 ram 3200mhz /\n",
    "its great for this price since i could have built the same thing as a pc for 30,000 rupees /\n",
    "i will strongly recommend to buy it from flipkart since it is cheaper their compared to other places like amazon /\n",
    "I am amazed with this laptop, thanks flipkart and zebronic for this deal\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "14208d08-65d2-4bd7-acd5-ffdac1656522",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationSummaryMemory(llm=chat, max_token_limit = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "8318ec34-26b5-478d-a10e-d10187ea922a",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.save_context({'input':'what is the review about?'},\n",
    "                   {'output': customer_review})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "e26c8323-50b6-4234-bad3-d3a736f8f8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "rev = memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "e147456e-6ed0-4da4-b08b-0c6486b5479c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'history': 'Current summary: None\\n\\nNew lines of conversation:\\nHuman: what is the review about?\\nAI: I recently bought the Zebronics S3 Laptop for 23,700 rupees / for this price I got an I3 12th gen 1215U processor / 8 GB ddr4 ram 3200mhz / its great for this price since i could have built the same thing as a pc for 30,000 rupees / i will strongly recommend to buy it from flipkart since it is cheaper their compared to other places like amazon / I am amazed with this laptop, thanks flipkart and zebronic for this deal\\n\\nNew summary: The human asks what the review is about, and the AI shares a review of the Zebronics S3 Laptop, highlighting its affordable price, specifications, and recommendation to buy it from Flipkart.'}\n"
     ]
    }
   ],
   "source": [
    "print(rev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "4860a05e-6c06-4b67-83f3-fa7be51c9309",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation = ConversationChain(\n",
    "    llm=chat, \n",
    "    memory = memory,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "f844987e-0df6-4aa2-9d1f-ba53f921814e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'Current summary: None\\n\\nNew lines of conversation:\\nHuman: what is the review about?\\nAI: I recently bought the Zebronics S3 Laptop for 23,700 rupees / for this price I got an I3 12th gen 1215U processor / 8 GB ddr4 ram 3200mhz / its great for this price since i could have built the same thing as a pc for 30,000 rupees / i will strongly recommend to buy it from flipkart since it is cheaper their compared to other places like amazon / I am amazed with this laptop, thanks flipkart and zebronic for this deal\\n\\nNew summary: The human asks what the review is about, and the AI shares a review of the Zebronics S3 Laptop, highlighting its affordable price, specifications, and recommendation to buy it from Flipkart.'}"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "c14494ed-118a-4283-b171-d95f3d7feddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Current summary: None\n",
      "\n",
      "New lines of conversation:\n",
      "Human: what is the review about?\n",
      "AI: I recently bought the Zebronics S3 Laptop for 23,700 rupees / for this price I got an I3 12th gen 1215U processor / 8 GB ddr4 ram 3200mhz / its great for this price since i could have built the same thing as a pc for 30,000 rupees / i will strongly recommend to buy it from flipkart since it is cheaper their compared to other places like amazon / I am amazed with this laptop, thanks flipkart and zebronic for this deal\n",
      "\n",
      "New summary: The human asks what the review is about, and the AI shares a review of the Zebronics S3 Laptop, highlighting its affordable price, specifications, and recommendation to buy it from Flipkart.\n",
      "Human: What are the specs of the pc?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"The specs of the Zebronics S3 Laptop are: Intel Core i3 12th gen 1215U processor, 8 GB DDR4 RAM with a speed of 3200 MHz, and I'm not sure about the storage capacity as it wasn't mentioned in the review.\""
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"What are the specs of the pc?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "8877e743-22dc-4c51-b58c-5180c88cf194",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Current summary: The human asks what the review is about, and the AI shares a review of the Zebronics S3 Laptop, highlighting its affordable price, specifications, and recommendation to buy it from Flipkart.\n",
      "\n",
      "New lines of conversation:\n",
      "Human: What are the specs of the pc?\n",
      "AI: The specs of the Zebronics S3 Laptop are: Intel Core i3 12th gen 1215U processor, 8 GB DDR4 RAM with a speed of 3200 MHz, and I'm not sure about the storage capacity as it wasn't mentioned in the review.\n",
      "\n",
      "New summary: The human asks what the review is about, and the AI shares a review of the Zebronics S3 Laptop, highlighting its affordable price, specifications, and recommendation to buy it from Flipkart. The AI also provides the laptop's specs, including the Intel Core i3 12th gen 1215U processor, 8 GB DDR4 RAM with a speed of 3200 MHz, but notes that the storage capacity is unknown as it was not mentioned in the review.\n",
      "Human: name of the place the user bought the laptop from?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The user bought the Zebronics S3 Laptop from Flipkart, which is a popular online shopping platform in India.'"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"name of the place the user bought the laptop from?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e4d34e-c403-452c-90a8-7b4b90a3b603",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
