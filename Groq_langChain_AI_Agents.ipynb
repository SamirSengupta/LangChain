{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53513fa3-9a4d-44ee-9707-3a5f847e6391",
   "metadata": {},
   "outputs": [],
   "source": [
    "from api_key import api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a97d8496-6c25-447e-b6e6-69cb864a2482",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0e663258-f5a1-4273-baa5-cc043d6aeb58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI don't have any prior knowledge about LangChain. I should look it up.\n",
      "Action: Wikipedia\n",
      "Action Input: LangChain\n",
      "\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mPage: LangChain\n",
      "Summary: LangChain is a framework designed to simplify the creation of applications using large language models (LLMs). As a language model integration framework, LangChain's use-cases largely overlap with those of language models in general, including document analysis and summarization, chatbots, and code analysis.\n",
      "\n",
      "\n",
      "\n",
      "Page: DataStax\n",
      "Summary: DataStax, Inc. is a real-time data for AI company based in Santa Clara, California. Its product Astra DB is a cloud database-as-a-service based on Apache Cassandra. DataStax also offers DataStax Enterprise (DSE), an on-premises database built on Apache Cassandra, and Astra Streaming, a messaging and event streaming cloud service based on Apache Pulsar. As of June 2022, the company has roughly 800 customers distributed in over 50 countries.\n",
      "\n",
      "Page: Sentence embedding\n",
      "Summary: In natural language processing, a sentence embedding refers to a numeric representation of a sentence in the form of a vector of real numbers which encodes meaningful semantic information.\n",
      "State of the art embeddings are based on the learned hidden layer representation of dedicated sentence transformer models. BERT pioneered an approach involving the use of a dedicated [CLS] token prepended to the beginning of each sentence inputted into the model; the final hidden state vector of this token encodes information about the sentence and can be fine-tuned for use in sentence classification tasks. In practice however, BERT's sentence embedding with the [CLS] token achieves poor performance, often worse than simply averaging non-contextual word embeddings. SBERT later achieved superior sentence embedding performance by fine tuning BERT's [CLS] token embeddings through the usage of a siamese neural network architecture on the SNLI dataset. \n",
      "Other approaches are loosely based on the idea of distributional semantics applied to sentences. Skip-Thought trains an encoder-decoder structure for the task of neighboring sentences predictions. Though this has been shown to achieve worse performance than approaches such as InferSent or SBERT. \n",
      "An alternative direction is to aggregate word embeddings, such as those returned by Word2vec, into sentence embeddings. The most straightforward approach is to simply compute the average of word vectors, known as continuous bag-of-words (CBOW). However, more elaborate solutions based on word vector quantization have also been proposed. One such approach is the vector of locally aggregated word embeddings (VLAWE), which demonstrated performance improvements in downstream text classification tasks.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI now know the final answer\n",
      "Final Answer: LangChain is a framework designed to simplify the creation of applications using large language models. It is used for various applications such as document analysis and summarization, chatbots, and code analysis. In the context of language models, sentence embedding refers to a numeric representation of a sentence that encodes meaningful semantic information. State-of-the-art sentence embeddings are based on learned hidden layer representations of dedicated sentence transformer models. Approaches such as BERT, InferSent, and SBERT have been used to achieve superior sentence embedding performance.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "LangChain is a framework designed to simplify the creation of applications using large language models. It is used for various applications such as document analysis and summarization, chatbots, and code analysis. In the context of language models, sentence embedding refers to a numeric representation of a sentence that encodes meaningful semantic information. State-of-the-art sentence embeddings are based on learned hidden layer representations of dedicated sentence transformer models. Approaches such as BERT, InferSent, and SBERT have been used to achieve superior sentence embedding performance.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain.agents import Tool\n",
    "from langchain.agents import initialize_agent\n",
    "from langchain.agents import AgentType\n",
    "from langchain.utilities import WikipediaAPIWrapper\n",
    "\n",
    "# Set the Groq API key from an environment variable\n",
    "GROQ_API_KEY = api\n",
    "\n",
    "# Initialize ChatGroq with the API key\n",
    "llm = ChatGroq(api_key=GROQ_API_KEY)\n",
    "\n",
    "# Initialize Wikipedia tool\n",
    "wiki = WikipediaAPIWrapper()\n",
    "\n",
    "# Define tools available to the agent\n",
    "tools = [\n",
    "    Tool(\n",
    "        name=\"Wikipedia\",\n",
    "        func=wiki.run,\n",
    "        description=\"Useful for when you need to answer general questions about people, places, organizations, historical events, scientific concepts etc. Input should be a search term.\"\n",
    "    )\n",
    "]\n",
    "\n",
    "# Create the agent\n",
    "agent = initialize_agent(tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True)\n",
    "\n",
    "# Query the agent\n",
    "query = \"What is LangChain?\"\n",
    "result = agent.run(query)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0f3721-c450-4d40-ab47-d3d4c4c854fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
